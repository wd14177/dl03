{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "614bfa7c",
   "metadata": {},
   "source": [
    "# Skin Dideases 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664dd4e4",
   "metadata": {},
   "source": [
    "1. 전이학습\n",
    "2. 파인튜닝\n",
    "3. 3가지 이상의 모델로 학습\n",
    "4. 체크포인트 저장\n",
    "5. 학습결과 시각화(텐서보드 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")\n",
    "# 환경 셋업 및 라이브러리 임포트\n",
    "import torch\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "import torch.nn as nn\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "import torch.optim as optim\n",
    "print(f'CUDA device count: {torch.cuda.device_count()}')\n",
    "import torchvision\n",
    "print(f'Torchvision version: {torchvision.__version__}')\n",
    "import torchvision.transforms as transforms\n",
    "print(\"Torchvision transforms\")\n",
    "from torch.utils.data import DataLoader\n",
    "print(f'Torch DataLoader version: {DataLoader.__module__}')\n",
    "from torchvision import datasets, models\n",
    "print('Torchvision ')\n",
    "import os\n",
    "print('OS module')\n",
    "import time\n",
    "print('Time module')\n",
    "import shutil\n",
    "print('Shutil module')\n",
    "import random\n",
    "print('Random module')\n",
    "import numpy as np\n",
    "print('Numpy ')\n",
    "from pathlib import Path\n",
    "print('Pathlib')\n",
    "print(\"=\" * 50)\n",
    "print(\"All libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40572d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random, shutil\n",
    "\n",
    "# 원본 데이터: ./data/skin/train/<class>/*.*\n",
    "src_root = Path(\"./data/skin\")\n",
    "src_train = src_root / \"train\"\n",
    "\n",
    "# 목적지: ./dataset/skin/train, ./dataset/skin/test\n",
    "dst_train_root = Path(\"./dataset/skin/train\")\n",
    "dst_test_root  = Path(\"./dataset/skin/test\")\n",
    "\n",
    "train_ratio = 0.8\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "\n",
    "valid_ext = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
    "\n",
    "# --- sanity check ---\n",
    "assert src_root.exists(), f\"src_root not found: {src_root.resolve()}\"\n",
    "assert src_train.exists(), f\"src_train not found: {src_train.resolve()}\"\n",
    "\n",
    "class_dirs = [d for d in src_train.iterdir() if d.is_dir()]\n",
    "print(\"Found classes:\", [d.name for d in class_dirs])\n",
    "\n",
    "for class_dir in class_dirs:\n",
    "    # 대상 클래스 폴더 생성\n",
    "    (dst_train_root / class_dir.name).mkdir(parents=True, exist_ok=True)\n",
    "    (dst_test_root  / class_dir.name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 이미지 수집(확장자 대소문자 대응)\n",
    "    files = [p for p in class_dir.iterdir()\n",
    "             if p.is_file() and p.suffix.lower() in valid_ext]\n",
    "\n",
    "    if len(files) == 0:\n",
    "        print(f\"[WARN] no valid images in: {class_dir}\")\n",
    "        continue\n",
    "\n",
    "    random.shuffle(files)\n",
    "    n_train = int(len(files) * train_ratio)\n",
    "    train_files = files[:n_train]\n",
    "    test_files  = files[n_train:]\n",
    "\n",
    "    # 복사\n",
    "    for p in train_files:\n",
    "        shutil.copy2(p, dst_train_root / class_dir.name / p.name)\n",
    "    for p in test_files:\n",
    "        shutil.copy2(p, dst_test_root / class_dir.name / p.name)\n",
    "\n",
    "    print(f\"{class_dir.name}: total={len(files)}, train={len(train_files)}, test={len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2264b647",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = Path(\"./dataset/skin/train\")\n",
    "test_dir  = Path(\"./dataset/skin/test\")\n",
    "\n",
    "valid_ext = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
    "\n",
    "# 데이터 전처리\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ColorJitter(0.15, 0.15, 0.10, 0.02),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225)),\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225)),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=str(train_dir), transform=train_transform)\n",
    "test_dataset  = datasets.ImageFolder(root=str(test_dir),  transform=eval_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True,\n",
    "                          num_workers=2, persistent_workers=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=16, shuffle=False,\n",
    "                          num_workers=2, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a93809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda 설정\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "print(f'Using device: {device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f952e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.class_to_idx)\n",
    "print(test_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b20171f",
   "metadata": {},
   "source": [
    "# 전이학습\n",
    "### 모델 1 - EfficientNetV2-S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49d0a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전이학습 모델 1 - EfficientNetV2-S 모델 불러오기, pretrained=True로 사전학습된 가중치 로드\n",
    "model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT).to(device)\n",
    "print(\"EfficientNetV2-S model loaded\")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0005eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트 및 텐서보드 콜백\n",
    "checkpoint_path = \"./checkpoints/efficientnetv2_s.pth\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1011f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier 외 모델의 모든 파라미터 동결\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# classifier 교체\n",
    "in_features = model.classifier[1].in_features\n",
    "\n",
    "model.classifier[1] = nn.Linear(in_features, 5)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# classifier만 학습 가능\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ecaad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad) # 각 파라미터의 requires_grad 상태 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f910a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실과 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e3067e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# cuda 사용\n",
    "import torch\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 루프: 체크포인트, 텐서보드, tqdm 진행바\n",
    "import tqdm\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in tqdm.tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "    # 체크포인트 저장\n",
    "    torch.save(model.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b43dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "img, lablel = train_dataset[92]\n",
    "print(img.shape, lablel)\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.title(f'Label: {lablel}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b4d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d6d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝 준비: 뒤쪽 블록만 unfreeze\n",
    "# 1) 먼저 전부 freeze\n",
    "for p in model.features.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# 2) 마지막 N개 블록 unfreeze\n",
    "N = 2\n",
    "for block in list(model.features.children())[-N:]:\n",
    "    for p in block.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "# 3) classifier는 계속 학습\n",
    "for p in model.classifier.parameters():\n",
    "    p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BatchNorm 처리\n",
    "import torch.nn as nn\n",
    "\n",
    "def set_bn_eval(m):\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        m.eval()\n",
    "\n",
    "model.apply(set_bn_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer 재설정 (unfreeze된 파라미터만)\n",
    "import torch.optim as optim\n",
    "\n",
    "backbone_params = [p for p in model.features.parameters() if p.requires_grad]\n",
    "head_params = [p for p in model.classifier.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    [\n",
    "        {\"params\": backbone_params, \"lr\": 2e-5},\n",
    "        {\"params\": head_params, \"lr\": 2e-4},\n",
    "    ],\n",
    "    weight_decay=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8358fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad) # 각 파라미터의 requires_grad 상태 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcced76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝 학습 루프\n",
    "fine_tune_epochs = 10\n",
    "\n",
    "for epoch in range(fine_tune_epochs):\n",
    "    model.train()\n",
    "    model.apply(set_bn_eval)  # BN 고정 유지\n",
    "\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        pred = outputs.argmax(dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels).sum().item()\n",
    "\n",
    "    print(f\"[FT {epoch+1}/{fine_tune_epochs}] loss={running_loss/len(train_dataset):.4f}, acc={correct/total:.4f}\")\n",
    "\n",
    "    # 체크포인트 (val 기준이 제일 좋지만, 최소한 epoch별 저장)\n",
    "    torch.save(model.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d16b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝 모델 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca19bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "torch.save(model.state_dict(), 'fine_tuned_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 파인튜닝 모델 불러와서 새로운 데이터셋으로 평가\n",
    "model_path = \"./fine_tuned_model.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bfea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터 불러오기\n",
    "new_data_dir = Path(\"data/skin_test\")\n",
    "new_dataset = datasets.ImageFolder(root=new_data_dir, transform=eval_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c7411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터로 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in DataLoader(new_dataset, batch_size=32, shuffle=False):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9376b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝 2 준비: 뒤쪽 블록만 unfreeze\n",
    "# 1) 먼저 전부 freeze\n",
    "for p in model.features.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# 2) 마지막 N개 블록 unfreeze\n",
    "N = 4\n",
    "for block in list(model.features.children())[-N:]:\n",
    "    for p in block.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "# 3) classifier는 계속 학습\n",
    "for p in model.classifier.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "# BatchNorm 처리\n",
    "import torch.nn as nn\n",
    "\n",
    "def set_bn_eval(m):\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        m.eval()\n",
    "\n",
    "model.apply(set_bn_eval)\n",
    "\n",
    "# optimizer 재설정 (unfreeze된 파라미터만)\n",
    "import torch.optim as optim\n",
    "\n",
    "backbone_params = [p for p in model.features.parameters() if p.requires_grad]\n",
    "head_params = [p for p in model.classifier.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    [\n",
    "        {\"params\": backbone_params, \"lr\": 3e-5},\n",
    "        {\"params\": head_params, \"lr\": 3e-4},\n",
    "    ],\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad) # 각 파라미터의 requires_grad 상태 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7799c0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝 학습 루프\n",
    "fine_tune_epochs = 10\n",
    "\n",
    "# tqdm 진행바 추가\n",
    "import tqdm\n",
    "\n",
    "for epoch in range(fine_tune_epochs):\n",
    "    model.train()\n",
    "    model.apply(set_bn_eval)  # BN 고정 유지\n",
    "\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    pbar = tqdm.tqdm(train_loader, desc=f\"Fine-tuning Epoch {epoch+1}\")\n",
    "    for inputs, labels in pbar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        pred = outputs.argmax(dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels).sum().item()\n",
    "\n",
    "    print(f\"[FT {epoch+1}/{fine_tune_epochs}] loss={running_loss/len(train_dataset):.4f}, acc={correct/total:.4f}\")\n",
    "\n",
    "    # 체크포인트 (val 기준이 제일 좋지만, 최소한 epoch별 저장)\n",
    "    torch.save(model.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda30ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝 모델 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "test_acc = correct / total\n",
    "print(f\"Dataset Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# 새로운 데이터로 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in DataLoader(new_dataset, batch_size=32, shuffle=False):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "test_acc = correct / total\n",
    "print(f\"New Dataset Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e48cb9e",
   "metadata": {},
   "source": [
    "### 모델 2 - ConvNeXt-Tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00419e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기: convnext_tiny\n",
    "model = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.DEFAULT)\n",
    "\n",
    "# head 교체\n",
    "in_features = model.classifier[2].in_features\n",
    "model.classifier[2] = nn.Linear(in_features, 5)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6f5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone 동결\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad) # 각 파라미터의 requires_grad 상태 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06af6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer 설정\n",
    "optimizer = optim.AdamW(model.classifier.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a72824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 변경: convnext_tiny는 224x224, EfficientNetV2-S는 384x384\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # 이미지 크기 조정\n",
    "    transforms.ToTensor(), # 텐서로 변환\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # 정규화\n",
    "])\n",
    "\n",
    "weights = models.ConvNeXt_Tiny_Weights.DEFAULT\n",
    "preprocess = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3cab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 루프: 체크포인트, 텐서보드, tqdm 진행바\n",
    "num_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in tqdm.tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "    # 체크포인트 저장\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': epoch_loss,\n",
    "        'accuracy': epoch_acc\n",
    "    }\n",
    "    torch.save(checkpoint, f'checkpoint_epoch_{epoch+1}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207e72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169e0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터 불러오기\n",
    "new_data_dir = Path(\"./data/skin_test\")\n",
    "new_dataset = datasets.ImageFolder(root=new_data_dir, transform=transform)\n",
    "\n",
    "# 새로운 데이터로 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in DataLoader(new_dataset, batch_size=32, shuffle=False):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        img_grid = torchvision.utils.make_grid(inputs.cpu())\n",
    "        plt.imshow(img_grid.permute(1,2,0))\n",
    "        plt.title(f'Predicted: {new_dataset.classes[predicted[0]]}, Actual: {new_dataset.classes[labels[0]]}')\n",
    "        plt.show()\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51778712",
   "metadata": {},
   "source": [
    "### 모델 3 - MobileNetV3-Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425bad59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl03",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
