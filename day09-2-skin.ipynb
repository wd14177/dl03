{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "614bfa7c",
   "metadata": {},
   "source": [
    "# Skin Dideases 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664dd4e4",
   "metadata": {},
   "source": [
    "1. 전이학습\n",
    "2. 파인튜닝\n",
    "3. 3가지 이상의 모델로 학습\n",
    "4. 체크포인트 저장\n",
    "5. 학습결과 시각화(텐서보드 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ee5b034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0666d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.10.0\n",
      "CUDA available: False\n",
      "CUDA device count: 0\n",
      "Torchvision version: 0.25.0\n",
      "Torchvision transforms\n",
      "Torch DataLoader version: torch.utils.data.dataloader\n",
      "Torchvision \n",
      "OS module\n",
      "Time module\n",
      "Shutil module\n",
      "Random module\n",
      "Numpy \n",
      "Pathlib\n",
      "==================================================\n",
      "All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# 환경 셋업 및 라이브러리 임포트\n",
    "import torch\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "import torch.nn as nn\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "import torch.optim as optim\n",
    "print(f'CUDA device count: {torch.cuda.device_count()}')\n",
    "import torchvision\n",
    "print(f'Torchvision version: {torchvision.__version__}')\n",
    "import torchvision.transforms as transforms\n",
    "print(\"Torchvision transforms\")\n",
    "from torch.utils.data import DataLoader\n",
    "print(f'Torch DataLoader version: {DataLoader.__module__}')\n",
    "from torchvision import datasets, models\n",
    "print('Torchvision ')\n",
    "import os\n",
    "print('OS module')\n",
    "import time\n",
    "print('Time module')\n",
    "import shutil\n",
    "print('Shutil module')\n",
    "import random\n",
    "print('Random module')\n",
    "import numpy as np\n",
    "print('Numpy ')\n",
    "from pathlib import Path\n",
    "print('Pathlib')\n",
    "print(\"=\" * 50)\n",
    "print(\"All libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40572d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split: ./data/skin/train의 데이터를 copy --> ./dataset/skin/ 폴더 내 train/test 폴더 내 각 클래스별 폴더로 나누기\n",
    "# 원본 데이터: ./data/skin/train/<class>/*.*\n",
    "src_root = Path(\"./data/skin\")\n",
    "\n",
    "# 목적지: ./dataset/skin/train, ./dataset/skin/test\n",
    "dst_train_root = Path(\"./dataset/skin/train\")\n",
    "dst_test_root  = Path(\"./dataset/skin/test\")\n",
    "\n",
    "train_ratio = 0.8\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "\n",
    "# 허용 확장자\n",
    "valid_ext = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e8bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 폴더만 추출\n",
    "classes = [p for p in src_root.iterdir() if p.is_dir()]\n",
    "\n",
    "for cls_path in classes:\n",
    "    cls_name = cls_path.name\n",
    "\n",
    "    # 이미지 파일만 필터링\n",
    "    images = [p for p in cls_path.iterdir() if p.is_file() and p.suffix.lower() in valid_ext]\n",
    "\n",
    "    # 셔플\n",
    "    random.shuffle(images)\n",
    "\n",
    "    n_total = len(images)\n",
    "    n_train = int(n_total * train_ratio)\n",
    "\n",
    "    train_images = images[:n_train]\n",
    "    test_images  = images[n_train:]\n",
    "\n",
    "    # 목적지 클래스 폴더 생성\n",
    "    (dst_train_root / cls_name).mkdir(parents=True, exist_ok=True)\n",
    "    (dst_test_root / cls_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 복사\n",
    "    for img_path in train_images:\n",
    "        shutil.copy2(img_path, dst_train_root / cls_name / img_path.name)\n",
    "\n",
    "    for img_path in test_images:\n",
    "        shutil.copy2(img_path, dst_test_root / cls_name / img_path.name)\n",
    "\n",
    "    print(f\"[{cls_name}] total={n_total}, train={len(train_images)}, test={len(test_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2264b647",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = dst_train_root\n",
    "test_dir = dst_test_root\n",
    "\n",
    "# 데이터 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # 이미지 크기 조정\n",
    "    transforms.ToTensor(), # 텐서로 변환\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # 정규화\n",
    "])\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform) # train 데이터셋\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform) # test 데이터셋\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) # train 데이터로더\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) # test 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a93809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f952e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b20171f",
   "metadata": {},
   "source": [
    "# 전이학습\n",
    "### 모델 1 - EfficientNetV2-S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49d0a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전이학습 모델 1 - EfficientNetV2-S 모델 불러오기, pretrained=True로 사전학습된 가중치 로드\n",
    "model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT).to(device)\n",
    "print(\"EfficientNetV2-S model loaded\")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0005eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트 및 텐서보드 콜백\n",
    "checkpoint_path = \"./checkpoints/efficientnetv2_s.pth\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1011f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier 외 모델의 모든 파라미터 동결\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# classifier 교체\n",
    "in_features = model.classifier[1].in_features\n",
    "\n",
    "model.classifier[1] = nn.Linear(in_features, 5)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# classifier만 학습 가능\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ecaad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad) # 각 파라미터의 requires_grad 상태 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f910a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실과 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 루프: 체크포인트, 텐서보드, tqdm 진행바\n",
    "import tqdm\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in tqdm.tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "    # 체크포인트 저장\n",
    "    torch.save(model.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2983102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서보드 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b43dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "img, lablel = train_dataset[92]\n",
    "print(img.shape, lablel)\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.title(f'Label: {lablel}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b4d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        img_grid = torchvision.utils.make_grid(inputs.cpu())\n",
    "        plt.imshow(img_grid.permute(1,2,0))\n",
    "        plt.title(f'Predicted: {train_dataset.classes[predicted[0]]}, Actual: {train_dataset.classes[labels[0]]}')\n",
    "        plt.show()\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d8f07c",
   "metadata": {},
   "source": [
    "- 파인튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d6d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝 준비: 뒤쪽 블록만 unfreeze\n",
    "# 1) 먼저 전부 freeze\n",
    "for p in model.features.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# 2) 마지막 N개 블록 unfreeze\n",
    "N = 2\n",
    "for block in list(model.features.children())[-N:]:\n",
    "    for p in block.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "# 3) classifier는 계속 학습\n",
    "for p in model.classifier.parameters():\n",
    "    p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BatchNorm 처리\n",
    "import torch.nn as nn\n",
    "\n",
    "def set_bn_eval(m):\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        m.eval()\n",
    "\n",
    "model.apply(set_bn_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer 재설정 (unfreeze된 파라미터만)\n",
    "import torch.optim as optim\n",
    "\n",
    "backbone_params = [p for p in model.features.parameters() if p.requires_grad]\n",
    "head_params = [p for p in model.classifier.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    [\n",
    "        {\"params\": backbone_params, \"lr\": 2e-5},\n",
    "        {\"params\": head_params, \"lr\": 2e-4},\n",
    "    ],\n",
    "    weight_decay=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8358fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad) # 각 파라미터의 requires_grad 상태 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcced76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝 학습 루프\n",
    "fine_tune_epochs = 15\n",
    "\n",
    "for epoch in range(fine_tune_epochs):\n",
    "    model.train()\n",
    "    model.apply(set_bn_eval)  # BN 고정 유지\n",
    "\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        pred = outputs.argmax(dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels).sum().item()\n",
    "\n",
    "    print(f\"[FT {epoch+1}/{fine_tune_epochs}] loss={running_loss/len(train_dataset):.4f}, acc={correct/total:.4f}\")\n",
    "\n",
    "    # 체크포인트 (val 기준이 제일 좋지만, 최소한 epoch별 저장)\n",
    "    torch.save(model.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d16b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝 모델 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca19bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "torch.save(model.state_dict(), 'fine_tuned_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝 모델 불러와서 새로운 데이터셋으로 평가\n",
    "model_path = \"./fine_tuned_model.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bfea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터 불러오기\n",
    "new_data_dir = Path(\"./data/skin_test\")\n",
    "new_dataset = datasets.ImageFolder(root=new_data_dir, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae4e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # 이미지 크기 조정\n",
    "    transforms.ToTensor(), # 텐서로 변환\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # 정규화\n",
    "])\n",
    "new_dataset = datasets.ImageFolder(root=new_data_dir, transform=transform)\n",
    "new_loader = DataLoader(new_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c7411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터로 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in DataLoader(new_dataset, batch_size=32, shuffle=False):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        img_grid = torchvision.utils.make_grid(inputs.cpu())\n",
    "        plt.imshow(img_grid.permute(1,2,0))\n",
    "        plt.title(f'Predicted: {new_dataset.classes[predicted[0]]}, Actual: {new_dataset.classes[labels[0]]}')\n",
    "        plt.show()\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e48cb9e",
   "metadata": {},
   "source": [
    "### 모델 2 - ConvNeXt-Tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00419e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기: convnext_tiny\n",
    "model = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.DEFAULT)\n",
    "\n",
    "# head 교체\n",
    "in_features = model.classifier[2].in_features\n",
    "model.classifier[2] = nn.Linear(in_features, 5)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6f5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone 동결\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad) # 각 파라미터의 requires_grad 상태 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06af6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer 설정\n",
    "optimizer = optim.AdamW(model.classifier.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a72824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 변경: convnext_tiny는 224x224, EfficientNetV2-S는 384x384\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # 이미지 크기 조정\n",
    "    transforms.ToTensor(), # 텐서로 변환\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # 정규화\n",
    "])\n",
    "\n",
    "weights = models.ConvNeXt_Tiny_Weights.DEFAULT\n",
    "preprocess = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3cab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 루프: 체크포인트, 텐서보드, tqdm 진행바\n",
    "num_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in tqdm.tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "    # 체크포인트 저장\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': epoch_loss,\n",
    "        'accuracy': epoch_acc\n",
    "    }\n",
    "    torch.save(checkpoint, f'checkpoint_epoch_{epoch+1}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207e72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169e0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터 불러오기\n",
    "new_data_dir = Path(\"./data/skin_test\")\n",
    "new_dataset = datasets.ImageFolder(root=new_data_dir, transform=transform)\n",
    "\n",
    "# 새로운 데이터로 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in DataLoader(new_dataset, batch_size=32, shuffle=False):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        img_grid = torchvision.utils.make_grid(inputs.cpu())\n",
    "        plt.imshow(img_grid.permute(1,2,0))\n",
    "        plt.title(f'Predicted: {new_dataset.classes[predicted[0]]}, Actual: {new_dataset.classes[labels[0]]}')\n",
    "        plt.show()\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51778712",
   "metadata": {},
   "source": [
    "### 모델 3 - MobileNetV3-Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425bad59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl03",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
